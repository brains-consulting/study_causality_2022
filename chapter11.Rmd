---
title: |
  | 統計的因果推論の理論と実装
  |
  | Chapter11
  | 傾向スコアマッチング：ATT の推定
  |
  |
  |
author: "大隈 亮"
date: '2022-05-25 (Wed)'
output: 
  revealjs::revealjs_presentation:
    #self_contained: false
    transition: none
    highlight: pygments
    theme: white
    reveal_options:
      #autoSlide: 5000
      width: 1280
      height: 960
      control: true
    css: "for-revealjs.css"
    pandoc_args: [
      '--from', 'markdown+autolink_bare_uris+tex_math_single_backslash-implicit_figures'
      ]
editor_options: 
  markdown: 
    wrap: 72
---

# Index

## Index {#index_1}

-   Chapter11の目的

-   11.1　比較政治学における「よく似たシステムデザイン」

-   11.2　統計的因果推論における「マッチング」

-   11.3　推定対象

-   11.4　使用するデータ

-   11.5　ナイーブな比較と共分散分析

-   11.6　復元によるマッチングと非復元によるマッチング

-   11.7　距離

-   11.8　マッチング方法

-   11.9　 Rによる復元抽出の傾向スコアマッチング：ATTの推定

-   11.10　標準誤差について

-   11.11　傾向スコアによるバランシングの評価

-   11.12　シミュレーションによる性能比較

-   11.13　傾向スコアをマッチングに使うべきでない？

-   11.14　質的研究のためのマッチング


# Chapter11の目的 {#Ch_11_0}

## Chapter11の目的 {#Ch_11_0_1}

- 傾向スコアマッチング（propensity score matching）とは何かを具体的に解説する
  - マッチングとは何かを解説する
  - 近年ある、マッチングに傾向スコアを使うべきではないという主張の論点を解説する


# 11.1　比較政治学における「よく似たシステムデザイン」 {#Ch_11_1}

## 比較政治学の研究手法 {#ch_11_1_1}

マッチング研究手法の例として、比較政治学（comparative politics）の研究手法を確認する

比較政治学とは、いくつかの国を対象とすることで、政治・社会・経済的な事象について研究を行う政治学の一分野である
<br />
<span style="font-size: 80%;">
※ 研究の単位は国とは限らず、たとえば、日本政治であれば、都道府県単位であったり、市区町村であったりすることもあるが、国を単位とするものが典型例である
</span>


<br />
比較政治学における、研究手法には

- よく似たシステムデザイン（most similar systems design）

- 違ったシステムデザイン（most different systems design）

がある

<br />


これらは、John Stuart Millの

- 差異法（method of difference）

- 一致法（method of similarity）

を発展させたものである

## 比較政治学の研究手法とJohn Stuart Millの対応 {#ch_11_1_2}

名称が紛らわしいが

|比較政治学|Mill    |
|:-----------------|:-----------------|
|よく似たシステムデザイン|差異法|
|違ったシステムデザイン|一致法|

という対応となっている


<br />

本章の主題はマッチングであり、この観点から**よく似たシステムデザイン**が興味深い


## よく似たシステムデザインとは {#ch_11_1_3}

政治・社会・人口・経済・文化などのさまざまな要因について似ているが、結果変数と重要な要因について異なっている2つの国をマッチングする研究手法であり、

- スウェーデンとノルウェー
- 米国と英国
- 米国とカナダ

などが典型例として知られている

<br />
すなわち、「よく似たシステムデザイン」は、**定性的な質研究におけるマッチング手法**である


## よく似たシステムデザインの解説（1/2） {#ch_11_1_4}

Limはマイケル・ムーア監督の『ボウリング・フォー・コロンバイン』を例にして「よく似たシステムデザイン」を解説している

この作品は、コロンバイン高校銃乱射事件を題材とし、米国とカナダにおける銃犯罪率の発生率について考察したものと理解できる


## よく似たシステムデザインの解説（2/2） {#ch_11_1_5}

表11.1は、10項目の変数について、米国とカナダを5段階で評価したものである

<br />
表11.1

<center>

<img src="./img/list_11_1.png" style="border: none;">

</center>


表11.1から、米国とカナダは、多くの点で類似しているが、「銃関連の殺人事件率」と「恐怖と不安の文化」が大きく異なっていることがわかる

したがって、他の要因の影響を統制した上で、米国における「恐怖と不安の文化」こそが「銃関連の殺人事件率」の高さの原因であると主張された


## よく似たシステムデザインの適用の問題 {#ch_11_1_6}

しかしながら、「よく似たシステムデザイン」の適用は、場当たり的で体系的でないという批判がある

表11.1をよく見てみると、「人種・民族の多様性」はわずかに異なり、「社会保障の水準」も異なっている

よって、この分析から「恐怖と不安の文化」が「銃関連の殺人事件率」の原因と結論付けることはできない

すなわち、統計的因果推論の立場からは、**無交絡性の仮定が十分に満たされているとはいえない**のである

質的研究に置けるマッチングについては、本章の最後で改めて言及する



# 11.2　統計的因果推論における「マッチング」 {#Ch_11_2}

## 統計的因果推論における「マッチング」 {#Ch_11_2_1}

同じ個体に対して、処置を行い、かつ、処置を行わないことは不可能であった

この因果推論の根本的問題に立ち向かうために、研究実験では、**複数の個体を用意して、それらの個体を無作為に2つの集団に割付けることで、処置群と統制群という比較可能な集団を用意**していた

そのようにすることで、平均処置効果（ATE）を推定することが可能になった

しかしながら、観察研究では、処置の割り付けが無作為でないので、処置群と統制群をそのまま比較するだけでは、因果効果を適切に推定することができなかった

そこで、マッチングでは、実際には異なる個体同士について、**観測される共変量が同じ個体をペアにして、事実上の同じ個体として扱う**ことで、因果効果を適切に推定できるようにする

11.1節で見た「よく似たシステムデザイン」は、まさにマッチングの考え方を採用している研究デザインである


## 統計的因果推論における「マッチング」の具体例（1/2） {#Ch_11_2_2}

表11.2を例として、具体的に考える

このデータは、被験者10人の情報が記録されている

処置の有無が1と0で記録されており、結果が55から81までの数値で記録されている

また、これら以外に年齢と性別が共変量として記録されている

つまり、共変量$X$は2次元である

表11.2で、被験者1は処置を受けていない20歳男性であり、被験者9は処置を受けている20歳男性である

表11.2

<center>

<img src="./img/list_11_2.png" style="border: none;">

</center>


## 統計的因果推論における「マッチング」の具体例（2/2） {#Ch_11_2_3}

したがって、年齢と性別でマッチングした後のデータは、表11.3のとおりである

表11.3

<center>

<img src="./img/list_11_3.png" style="border: none;">


</center>


この2人をマッチングした理由は、年齢と性別が同じなのだから、「結果」の違い（$77 - 63 = 14$）は、年齢と性別が原因ではないと考えられるからである

ここで、**未観測の交絡因子がない**という仮定が正しければ、この2人の「結果」の違いは、「処置」の違いが原因であると主張できる

11.1節の例では研究の単位が国であり、米国とカナダが似ているものとしてマッチングされており、「恐怖と不安の文化」が処置で、「銃関連の殺人事件率」が結果だったわけである


## 統計的因果推論における適切な「マッチング」 {#Ch_11_2_4}


このような因果推論の妥当性は、**「未観測の交絡因子がないという仮定」の妥当性**に依存している

これは、すでに何度も見てきたとおり、式（11.1）の条件付き独立性（無交絡性）が満たされている必要がある

$$
\{Y(1), Y(0)\}\perp T|X \tag{11.1}
$$

そのためには、共変量 $X$ は、多変量である必要がある（9.3節参照）

<br />

今回の二変量では十分な情報を持っていないかもしれない

具体的に処置と結果が何を意味するかにもよるが、年齢と性別以外にも、身長、体重、年収、貯蓄、学歴、職歴、居住地など、さまざまな情報が交絡因子として存在している可能性がある

そこで、すでに10章で見たとおり、多変量の共変量 $X$ を条件としたときに、処置に割付けられる確率として単変量傾向スコアに情報を縮約することができる

傾向スコア定理により、傾向スコアが似ている者同士をマッチングすれば、処置群と対照群における多変量の共変量 $X$の分布は同じになると考えることができた

この傾向スコアが似ている個体同士をマッチングして分析を行う


# 11.3　推定対象 {#Ch_11_3}

## 推定対象 {#Ch_11_3_1}


2.4節と2.5節で検討した通り、統計的因果推論における推定対象（estimated）には、大きく分けて**平均処置効果（ATE）**と**処置群の平均処置効果（ATT）**があった

それぞれ、式（11.2）と式（11.3）のとおりであった

$$
\begin{align}
\tau_{ATE} & = E[Y_{i}(1) - Y_{i}(0)] = E[Y_{i}(1)] - E[Y_{i}(0)] \tag{11.2} \\
\tau_{ATT} & = E[Y_{i}(1) - Y_{i}(0) | T_{i} = 1] \\
& = E[Y_{i}(1) | T_{i} = 1] - E[Y_{i}(0) | T_{i} = 1] \tag{11.3}
\end{align}
$$

<br />

マッチングにおける推定対象は、ATEでなく、ATTである

なぜなら、**処置群における個体に対して、対照群からマッチングする候補を選んでくるため、マッチング後のデータは処置群の個体を中心として構成されているから**である

<br />
また、9.4節で指摘した通り、共分散分析では、ATEを推定することができるが、ATTは推定できない

ATTを推定したい場合には、本章で扱う傾向スコアマッチングを用いることができる

なお、傾向スコアによってATEを推定したい場合は、第12章で扱う傾向スコアによる層化解析（subclassification）、または傾向スコアによる重み付け方（weighting）を用いる


# 11.4　使用するデータ {#Ch_11_4}

##  使用するデータ {#Ch_11_4_1}


表11.4のとおりに、データを読み込む

共変量がx1からx6まで6個あるので、そのままマッチングするのは難しいだろう

表11.4 データ

```{r echo=TRUE}
rm(list = ls())
data11 <- read.csv("./causality-main/data11.csv")
attach(data11)
summary(data11)
```

##  使用するデータの生成プロセス（1/2） {#Ch_11_4_2}

このデータの生成プロセスは、以下のとおりである

共変量x1、x2、x3、x4、x5、x6は、平均値1、標準偏差1の多変量対数正規分布に従う乱数である

相関行列は、テプリッツ行列（Toeplitz matrix）として設定している

通常の分散共分散行列では、対角要素はすべて1.00で一定である

テプリッツ行列では、対角要素以外についても、対角線沿いの値が一定となる行列である


```{r echo=TRUE}
toeplitz(0.5^(0:5))
```


##  使用するデータの生成プロセス（2/2） {#Ch_11_4_3}

変数y0tとy1tは、潜在的結果変数である

本来は観測されないものであるが、ここではすべての値が観測されている状態である

式（11.4）のとおりに、y0tは $Y_{i}(0)$ として、y1tは $Y_{i}(1)$ として生成した

つまり、統制群と処置群で回帰係数が共通でないという設定である

ここで、誤差項 $\epsilon_{i}$ は、標準正規乱数である

$$
\begin{align}
Y_{i}(0) & = 1 + 1 X_{1i} - 3 X_{2i} + 5 X_{3i} + 7 X_{4i} + 9 X_{5i} + 11 X_{6i} + \epsilon_{i} \\
Y_{i}(1) & = 5 + 2 X_{1i} + 4 X_{2i} - 6 X_{3i} + 8 X_{4i} + 10 X_{5i} + 12 X_{6i} + \epsilon_{i}
\tag{11.4}
\end{align}
$$


<br />
変数y3は、観測された結果変数である

通常の解析では、この変数が観測される

変数t1は、処置の割り付けを表す二値変数である


##  処置の割り付けルール {#Ch_11_4_4}


処置の割り付けのルールは、式（11.5）のとおりである

ここで、$\rm{med} (Y_{i}(0))$ は $Y_{i}(0)$ の中央値を表し、$u_{1i}$ と $u_{2i}$ は区間[0, 1]の一様乱数である

つまり、$Y_{i}(0)$ が中央値より大きいとき50%の確率で $T_{i} = 1$ であり、$Y_{i}(0)$ が中央値以下のとき25%の確率で $T_{i} = 1$ である

また、$Y_{i}(0)$ が中央値より大きいとき50%の確率で $T_{i} = 0$ であり、$Y_{i}(0)$ が中央値以下のとき75%の確率で $T_{i} = 0$ である


$$
T_{i} =
\begin{cases}
{1 \quad \rm{if} \quad Y_{i}(0) > \rm{med}(Y_{i}(0)) \& u_{1i} \leq 0.50 \quad or \quad  Y_{i}(0) \leq \rm{med}(Y_{i}(0)) \& u_{2i} > 0.75 }  \\
{0 \quad \rm{if} \quad Y_{i}(0) > \rm{med}(Y_{i}(0)) \& u_{1i} > 0.50 \quad or \quad  Y_{i}(0) \leq \rm{med}(Y_{i}(0)) \& u_{2i} \leq 0.75 } \tag{11.5}
\end{cases}
$$

##  推定対象の真値の計算 {#Ch_11_4_5}


表11.5のとおり、推定対象の真値を計算する

表11.5 推定対象の真値
```{r echo=TRUE}
mean(y1t[t1==1]) - mean(y0t[t1==1])
mean(y1t) - mean(y0t)
```


1行目を実行すると、ATTの真値は2.889とわかる

ATTは、処置の割り付け変数t1が1のときの潜在的結果変数y1tの平均値と、処置の割付け変数1tが1のときの潜在的結果変数y0tの平均値との差である

<br />

2行目を実行すると、ATEの真値は3.756とわかる

ATEは、潜在的結果変数y1tの平均値と潜在的結果変数y0tの平均値との差である


# 11.5　ナイーブな比較と共分散分析 {#Ch_11_5}

## ナイーブな比較と共分散分析 {#Ch_11_5_1}

傾向スコアによるモデリングの前に、2群のナイーブな比較および、交差項を含まない共分散分析の結果を確認する

これらの結果はすでに解説した方法を活用することで再現できる

------------------------------------------------------------------------


```{r echo=TRUE}
summary(native1 <- lm(y3 ~ t1))
summary(ancova1 <- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6))
```


## ナイーブな比較と共分散分析 {#Ch_11_5_2}

ナイーブな比較結果は、15.8099で、ATEとATTのいずれと比較しても大きく偏っている様子がわかる

また、すでに述べたとおり、共分散分析ではATTを推定できない

ゆえに、共分散分析の推定結果3.4741は、ATTの真値2.889とかなり異なっている様子がわかる

また、すべての交差項を含めていないため、正しくモデリングされておらず、ATEの真値3.756についても正しく推定できていない

本章、および次章において、傾向スコアモデリングはATTとATEをフレキシブルに推定できることを示す


# 11.6　復元によるマッチングと非復元によるマッチング {#Ch_11_6}

## 復元によるマッチングと非復元によるマッチング（1/2） {#Ch_11_6_1}

本章では、data11を使って傾向スコアマッチングにより処置群の平均処置効果（ATT）の推定を行うが、その前に11.6節から11.8節において、いくつか確認すべき事項に触れておく

初級的な確率統計の授業や書籍において、箱からボールを取り出す方法について議論することがよくある

一度取り出したボールを箱に戻す抽出の仕方を**復元抽出**（sampling with replacement）といい、一度取り出したボールを箱に戻さない抽出の仕方を**非復元抽出**（sampling without replacement）といった

個体をペアにするには、マッチングの相手の選び方を復元するか、非復元とするかを考えなければいけない

※ RパッケージのMatchItのmatchit関数の引数として、replace=の右辺をTRUE（復元）またはFALSE（非復元）と設定する


## 復元によるマッチングと非復元によるマッチング（2/2） {#Ch_11_6_2}

表11.6を使って、男女のマッチングを例として、復元によるマッチングと非復元によるマッチングの違いを考える

ここでは、極めて単純に5人の男女を年齢だけでマッチングする

つまり、年齢の近い男女をペアにする

ここで、年齢が30歳以上離れた場合、マッチングの候補としては不適切と考えることにする

図11.6

<center>

<img src="./img/list_11_6.png" style="border: none;">

</center>


## 復元によるマッチング {#Ch_11_6_3}

まずは、復元の場合を考える

図11.6　（再掲）

<center>

<img src="./img/list_11_6.png" style="border: none;">

</center>

ID1は28歳の女性であり、ID3、ID4、ID5がマッチング候補の男性である

男性3人の中で、ID3の年齢が28歳なので、ID1とマッチングしてペアとする

次に、ID2は28歳の女性であり、**復元の場合には一度選ばれたID3も再び候補に含める**ので、ID3、ID4、ID5がマッチング候補の男性である

したがって、男性3人の中で、ID3の年齢が28歳なので、ID2とマッチングしてペアとする

よって、2組のペアが出来上がる


## 非復元によるマッチング {#Ch_11_6_4}

次に、非復元の場合を考える

図11.6　（再掲）

<center>

<img src="./img/list_11_6.png" style="border: none;">

</center>


先ほどと同様に、ID1の28歳の女性に対してID3の28歳の男性をマッチングしてペアとする

次にID2の28歳の女性に対してマッチング相手を探すが、**非復元の場合には一度選ばれたID3は候補者に含めない**ので、ID4とID5がマッチング候補の男性である

次点の候補としてはID4となるが、年齢が30歳以上離れた場合、マッチングの候補としては不適切と考えているため、適切なマッチングではない

よって、1組のペアが出来上がる


## 復元によるマッチングと非復元によるマッチングのまとめ {#Ch_11_6_5}

さて、現実のお見合い用マッチングアプリとしては、復元によるデータマッチングでは同じ人が2人以上とペアになってしまい、大変に困ったことになる

しかし、データ解析においては、**復元によるマッチングはデータに含まれる情報が無駄になりにくいという長所があり、解析結果の偏りが小さくなる傾向がある**

実際に今回の例では、復元では2組のペアが出来上がったが、非復元では1組のペアしか出来上がっておらず、非復元ではデータの情報を十分に活用できていない可能性がある

ただし、復元の場合、ID3の男性が2つのペアに登場するわけであるから、**マッチングされたデータは独立でなく、マッチングの重みを考慮するなどの必要があり、推定の仕方が複雑になる**という短所もある

<br />

非復元によるマッチングの方がより一般的という意見もあるが、どちらの方法も一長一短であるため、慎重に判断する必要がある

Gerifer（2020）は、非復元の場合にマッチングの重みを考慮に入れても入れなくても推定値に変化はなく、復元の場合にはマッチングの重みを考慮に入れる必要があるため、どちらの場合でもマッチングの重みを考慮に入れておけばよいとも述べている



# 11.7　距離 {#Ch_11_7}

## 距離 {#Ch_11_7_1}

マッチングの候補となる個体が似ていればペアとするわけであるが、その基準を決める必要がある

そして、その基準となるのが**個体間の距離**（distance）である

RパッケージMatchItのmatchit関数の引数として、distance=の右辺に距離を設定する

デフォルトはglmであり、これはロジスティック回帰によってモデル化した傾向スコアである

使用できる選択肢は、表11.7のとおりである


## matchit関数の引数distance {#Ch_11_7_2}

表11.7 distanceの引数

<center>

<img src="./img/list_11_7.png" style="border: none;">

</center>


引数glmからbartまでは、各々の手法からモデル化した傾向スコアを距離として用いる

つまり、傾向スコアの値が近いもの同士をペアにするということである

個体 $i$ と $j$ の距離は、傾向スコアの差の絶対値 $|e_{i} - e_{j}|$ によって測定される

引数glmとgamでは、リンク関数としてロジスティック回帰がデフォルトである

なお、引数mahalanobisでは、傾向スコアは計算されない


# 11.8　マッチング方法 {#Ch_11_8}

## マッチング方法 {#Ch_11_8_1}

マッチングをどうやって行うかについても考える必要がある

RパッケージのMatchItのmatchit関数の引数として、method=の右辺のマッチング方法として使用できる選択肢は、表11.8のとおりである

表11.8 methodの引数

<center>

<img src="./img/list_11_8.png" style="border: none;">

</center>

最近隣法マッチング（nearest neighbor matching）では、処置群に置ける各々の個体に対して、傾向スコアの値が近い個体を1つずつマッチングする

これは、貪欲マッチング（greedy matching）とも言われる方法で、個別の距離を最小化することを目指しており、必ずしもデータ全体での距離は最小化しない

最適ペアマッチング（optimal pair matching）は、マッチングされたすべてのペアに関して、平均絶対距離（average absolute distance）が最も小さくなるようにマッチングを行うものである

## 最近隣法（貪欲マッチング）と最適ペアマッチングの違い {#ch_11_8_2}

表11.9を例として、最近隣法（貪欲マッチング）と最適ペアマッチングの違いを確認する

処置群の個体1・個体2・個体3と統制群の個体4・個体5・個体6をマッチングすることを考える

ここでは、簡単のため、非復元のマッチングを考える

表11.9の数値は個体化の距離を表しているものとする

つまり、数字が小さいほど、個体間の距離が近く、似ている個体とみなされる

表11.9 距離行列の例

<center>

<img src="./img/list_11_9.png" style="border: none;">

</center>


## 最近隣法（貪欲マッチング）によるマッチング {#Ch_11_8_3}


最近隣法（貪欲マッチング）は、早い者勝ちの方法とも説明される


表11.9 距離行列の例

<center>

<img src="./img/list_11_9.png" style="border: none;">

</center>


表11.9において、もっとも小さな距離は個体1と個体5の距離0.1である

したがって、最初に個体1と個体5がペアとなる

次に小さな距離は個体2と個体5の距離0.2であるが、個体5はすでにペアになっており、非復元のマッチングを考えているので、この数字は無視する

次に小さな距離は個体3と個体6の0.3であるから、個体3と個体6をペアとする

残ったペアは、個体2と個体4であるが、この2つの個体の距離は100.0もある

結果として、距離の総和は、0.1 + 0.3 + 100.0 = 100.4であり、平均絶対距離は33.5と非常に大きい


## 最適ペアマッチングによるマッチング {#Ch_11_8_4}

最適ペアマッチングでは、平均絶対距離が最も小さくなるようにマッチングを行う方法であった

表11.9において、灰色セルで表されている対角線の距離の総和は0.4 + 0.2 + 0.3 = 0.9で、平均絶対距離は0.3となって、これが最も小さい


表11.9 距離行列の例

<center>

<img src="./img/list_11_9.png" style="border: none;">

</center>


個体1と個体4、個体2と個体5、個体3と個体6が最適なペアと判断される


## 最近隣法（貪欲マッチング）と最適ペアマッチングまとめ {#ch_11_8_5}

最近隣法（貪欲マッチング）は、個別の距離を最小化することを目指しており、必ずしもデータ全体での距離は最小化しないと述べた

よくマッチングされた個体を使いたいなら、最適マッチングが良いと指摘されている

最近隣法（貪欲マッチング）は、早い者勝ちの方法なので、結果として、個体をよくマッチングする方法として適切でないおそれがある

表11.9の例では、最初に選んだ個体1と個体5のペアを工程してしまって再検討しないため、結局、個体2と個体4はよくマッチングされていない個体のペアとなってしまったのである

傾向スコアの提案者ローゼンバウムは、非復元の最近隣法（貪欲マッチング）を直観的だが誤った手段と評している
（この件については、11.12節の議論も参照されたい）

## その他のマッチング方法（1/2） {#ch_11_8_6}

遺伝的マッチング（genetic matching）は、遺伝的探索アルゴリズム（genetic search algorithm）に基づいて、各々の共変量に対してマッチング後のバランスが最適となるような重みづけを使用する方法である

<br />

厳密マッチング（exact matching）は、共変量の値が正確に同じ値のペアを作成する方法である

表11.1、表11.2、表11.6で行ったマッチングは、厳密マッチングの例であるが、通常のデータ解析ではあまり使用する機会はないだろう

<br />

単純化厳密マッチング（CEM: coarsened exact matching）は、厳密マッチングの代替法として提案されたものである

連続変数で厳密マッチングを行うと、正確に同じ値の個体同士を見つけることができない場合が多い

このようなとき、連続変数をいくつかのカテゴリに分割してマッチングを行う

たとえば、年収という連続変数を「非常に少ない、少ない、普通、多い、非常に多い」などといった形でカテゴリ化することが考えられる

## その他のマッチング方法（2/2） {#ch_11_8_7}

傾向スコアのモデリングをする際には、処置群と統制群における各々の共変量の標準化平均差の絶対値が小さくなる手法がよいとされており、具体的には0.1未満になるような手法が推奨されている
（これについては、11.10節で再度検討する）

なお、引数subclassは、層化解析を意味するため、第12章で使用する

また、引数fullは、最適フルマッチングを意味するが、これも一種の層化解析である


# 11.9　Rによる復元抽出の傾向スコアマッチング：ATTの推定 {#Ch_11_9}

## Rによる復元抽出の傾向スコアマッチング：ATTの推定（1/2） {#Ch_11_9_1}

表11.4でRに読み込んだdata11の解析に戻る

表11.10のとおり、傾向スコアマッチングを実行して解析する

<br />

表11.10 傾向スコアマッチングによるATTの推定1

```{r echo=TRUE}
library(MatchIt)
m.out1 <- matchit(t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data=data11, replace=TRUE, distance="glm", method="nearest")
m.data1 <- match.data(m.out1)
model1 <- lm(y3 ~ t1, data=m.data1, weights=weights)
model2 <- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data=m.data1, weights=weights)
```


## Rによる復元抽出の傾向スコアマッチング：ATTの推定（2/2） {#Ch_11_9_2}

2行目で、matchit関数を使って、傾向スコアのモデル化を行う

構文は、matchit(処理の割り付け変数 ~ 共変量1 + 共変量2 + ..., data=データ名)である

3行目では、matchit関数の引数replaceの右辺をTRUEとして復元のマッチングを実行している

なお、FALSEとすれば非復元のマッチングである

引数distanceはデフォルトのglmを指定しており、ロジスティック回帰によって計算された傾向スコアを距離として用い、mathodの引数として、マッチング方法は、最近隣法（nearest）としている

4行目では、match.data関数を使って、マッチング後のデータを作成している

5行目のmodel1は、傾向スコアマッチング後のデータm.data1からATTの推定を行っている

また、6行目では、model2は傾向スコアマッチング後のデータm.data1から共分散分析を行っている

復元のマッチングなので、いずれの場合も、引数weightsにマッチングの重み（weights）を設定しておく


------------------------------------------------------------------------

モデル1

```{r echo=TRUE}
summary(model1)
```

------------------------------------------------------------------------

モデル2

```{r echo=TRUE}
summary(model2)
```

## マッチング後のデータを共分散分析する理由（1/2） {#Ch_11_9_3}

6行目で、マッチング後のデータを使って共分散分析を実行した理由を確認する

理論上では、傾向スコアマッチングによって共変量の影響によ偏りを除去してATTをできるため、マッチング後のデータを用いて単純に平均値の差を計算すればよい

それがモデル1である

<br />

しかし、**傾向スコアによって共変量のバランシングが取れているように見える場合でも、わずかなインバランスが残っている場合がある**

今回の例では、ATTの真値は2.889であった

解析モデルに共変量を取り込まないモデル1では、ATTの推定値は2.594で、やや過小な推定値となっている

傾向スコアマッチング後にも共変量の影響が残っている可能性があるため、解析モデルにも共変量を取り込むことが推奨される

傾向スコアマッチングを行ったあと、解析モデルにも共変量を取り込んだモデル2にによるATTの推定値は2.917で、適切に推定できている

このとき、特に交互作用項を気にせずに共変量を解析モデルに取り入れたが、正しい推定結果になっていることからも、傾向スコアモデリングは共分散分析よりもモデルの誤設定に強く、フレキシブルであることがわかる


## マッチング後のデータを共分散分析する理由（2/2） {#Ch_11_9_3}

なお、前節で議論したとおり、非復元による最近隣法（replace=FALSE, method="nearest"）は、不適切である可能性がある

実際に表11.11のとおりに実行すると、モデル3の推定値は6.027であり、モデル4の推定値は3.276であるから、いずれにしても過大推定になっている
(これについては、11.13節の議論も参照されたい)

<br />

表11.11　傾向スコアマッチングによるATTの推定2

```{r echo=TRUE}
m.out2 <- matchit(t1 ~ x1 + x2 + x3 + x4 + x5 + x6, data=data11, replace=FALSE, distance="glm", method="nearest")
m.data2 <- match.data(m.out2)
model3 <- lm(y3 ~ t1, data=m.data2, weights=weights)
model4 <- lm(y3 ~ t1 + x1 + x2 + x3 + x4 + x5 + x6, data=m.data2, weights=weights)
```

------------------------------------------------------------------------

モデル3

```{r echo=TRUE}
summary(model3)
```

------------------------------------------------------------------------

モデル4

```{r echo=TRUE}
summary(model4)
```



# 11.10　標準誤差について {#Ch_11_10}

## 標準誤差について（1/3） {#Ch_11_10_1}

傾向スコアマッチング後のデータ解析における標準誤差の扱いについては、近年、議論が続いている

論点は、**傾向スコアがモデルから計算されたことに起因する不確実性を標準誤差に反映させる必要があるかどうか**という点である

<br />
Stuartは、傾向スコアの真値を使用した場合と比べて、傾向スコアの予測値を使用した場合、標準誤差は大きくなる傾向があるため、信頼区間の幅が広くなるという意味での保守的な推定を行えるとし、特に標準誤差を修正する必要はないとしている

<br />
一方、Austin、Webster-Clark et al.、Shiba and Kawaharaは、標準誤差を推定する際に、データがマッチングされたという性質を反映させるべきだとしている

具体的に、Greiferは、どの個体がペアとなっているかの情報をクラスターとして、クラスターに頑健な標準誤差を用いることを推奨している

## 標準誤差について（2/3） {#Ch_11_10_2}

Rで実際に行うには、表11.12のようにすればよい

<br />

表11.12　クラスターに頑健な標準誤差を設定

```{r echo=TRUE}
library(lmtest); library(sandwich)
```

------------------------------------------------------------------------

推定値と標準誤差

```{r echo=TRUE}
coeftest(model2, vcov.=vcovCL, cluster=~weights)
```

<br />

95%信頼区間

```{r echo=TRUE}
coefci(model2, level=0.95, vcov.=vcovCL, cluster=~weights)
```

## 標準誤差について（3/3） {#Ch_11_10_3}

点推定値は以前と同じ2.917であるが、クラスターに頑健な標準誤差を使用したことで、標準誤差は0.675となっている

95%信頼区間は1.593～4.242である

ATTが0であれば効果がないという意味になるから、0が区間の中に入っていないため、帰無仮説を棄却して5%で統計的に優位な結論と言える

実際に、真値2.889は区間内に入っている



# 11.11　傾向スコアによるバランシングの評価 {#Ch_11_11}

## 傾向スコアによるバランシングの評価 {#Ch_11_11_1}

傾向スコアを使ってマッチングを実行する際には、共変量の分布が処置群と統制群でいかにバランシングしているかどうかを吟味する必要がある

つまり、処置群と統制群が十分に似ている状態になっているかどうかを確認する必要がある

<br />

表11.13のとおり、matchit関数による演算結果m.out1をsummary関数によって囲むことで、バランシングの評価指標を表示できる

指標の値が小さければ、バランシングがうまくとれていることを意味している

Std. Mean Diffの値が0に近く、Var. Ratioの値が1に近ければ、バランシングがとれていることを意味する

------------------------------------------------------------------------

表11.13　バランシングの評価：サマリー

```{r echo=TRUE}
summary(m.out1)
```

## バランシングの評価の可視化（1/2） {#Ch_11_11_2}

なお、Summary関数による出力は、情報が多すぎて分かりにくい

そこで、ラブプロット（love plot）という図で可視化して判断する

パッケージから簡便に表示させる方法もあるが、第20章において、欠測値を多重代入法で処理する場合にも使えるよう、表11.14のとおり、R関数dotchartを活用してスクラッチから実装する

------------------------------------------------------------------------

表11.14 ラブプロットによるバランシングの評価1

```{r echo=TRUE}
diffa <- abs(summary(m.out1)$sum.all[ ,3])
diffb <- abs(summary(m.out1)$sum.matched[ ,3])
diff1 <- rev(diffa)
diff2 <- rev(diffb)
maxx <- max(diff1, diff2)
labels0 <- rownames(summary(m.out1)$sum.all)
labels1 <- rev(labels0)
```

------------------------------------------------------------------------

```{r echo=TRUE}
dotchart(diff1, xlim=c(0, maxx), labels=c(labels1))
abline(v=0.00, col=8)
abline(v=0.10, col=8)
abline(v=0.05, lty=2, col=8)
par(new=TRUE)
dotchart(diff2, xlim=c(0, maxx), labels=c(labels1), pch=16, xlab="Absolute Standardized Mean Difference")
```

図11.1　ラブプロット1（●傾向スコアマッチング後、○傾向スコアマッチング前）

## バランシングの評価の可視化（2/2） {#Ch_11_11_3}

横軸は標準化平均差の絶対値（absolute standardized mean difference）を表しており、マッチング後●の方が、マッチング前○よりも平均差の絶対値が小さいので、処置群と統制群の分布の違いが小さくなってことが示されている

この値は0であることが理想的であり、0.1以下であることが望ましい

したがって、今回の傾向スコアマッチングでは、共変量の偏りは十分に是正されたことがわかる

<br />

もし標準化平均差の絶対値が0.1よりも大きい場合、両群がバランスするように、傾向スコアのモデルに高次の項、非線形の変換、交互作用項などを取り入れることが推奨される

つまり、表11.10のmatchit(t1 ~ x1 + x2 + ..., data=data11)の...の部分に高次の項や交互作用項などを追加したり、共変量（x1, x2など）を非線形に変換したりするということである


なお、ラブプロットは表11.15のとおり、1行で作成することもでき、出力結果は図11.1と基本的に同じ図である

ただし、表11.15のコードは、欠測データには対応できないため、第20章では、表11.14のコードを活用する

------------------------------------------------------------------------

表11.15　ラブプロットによるバランシングの評価2

```{r echo=TRUE}
plot(summary(m.out1), position=NULL)
```

図11.2　ラブプロット2（●傾向スコアマッチング後、○傾向スコアマッチング前）



# 11.12　シミュレーションによる性能比較 {#Ch_11_12}

## シミュレーションによる性能比較 {#Ch_11_12_1}

先のdata11と同じデータ生成メカニズムに従って、1万回のモンテカルロ・シミュレーションを行った結果が表11.16である

表11.16

<center>

<img src="./img/list_11_16.png" style="border: none;">

</center>

ナイーブな推定量は、大幅に偏っている

ここでは、共分散分析は、すべての交互作用項を正しく設定しているモデルであるが、共分散分析の推定対象はATEであるから、ATTの推定に関しては偏りがあることがわかる

4つの傾向スコアモデリングの中では、傾向スコアマッチングをしたあと、解析モデルにも共変量を含めているモデルの性能がよいことが示されている

ただし、この結果は絶対的な結果ではなく、あくまでもdata11と同じ環境下であればという条件付きである


## 傾向スコアマッチングと共分散分析 {#Ch_11_12_2}

上記のシミュレーションからわかるとおり、共分散分析はATEを推定対象としており、傾向スコアマッチングはATTを推定対象としてるという違いがある

さらに、傾向スコアの提案者ローゼンバウムによると、傾向スコアマッチングは、共分散分析と比較して、以下の通りの利点がある

共分散分析では、共変量に関してどの個体同士を比較したかがわからず、モデルが正しい場合に妥当な推定値が得られるだけである

一方、傾向スコアマッチングでは、共変量に関してどの個体同士が比較されたかを視覚的に確認できる
これは、共変量に関する調整を視覚的に評価できることを意味しており、傾向スコアマッチングの利点である



# 11.13　傾向スコアをマッチングに使うべきでない？ {#Ch_11_13}

## 傾向スコアをマッチングに使うべきでない？ {#Ch_11_13_1}

King and Nielsenは、「傾向をスコアマッチングに使うべきでない理由」というタイトルの論文を発表した

この研究内容は、2016年から公開されており、大きな話題となってきた

<br />

King and Nielsenによると、2019年現在、14万1千もの学術論文において傾向スコアマッチングが用いられてきたとされている

もしKing and Nielsenの主張が正しいとすれば、多くの実証研究の結果に疑念の生じる事態である

したがって、King and Nielsenの主張およびそれに対するいくつかの反論を確認しておく

## King and Nielsenの主張 {#Ch_11_13_2}

King and Nielsenの主張の要点は、以下のとおりである

マハラノビス距離マッチング（Mahalanobis distance matching）や単純化厳密マッチング(CEM)と比較して、傾向スコアマッチングでは、用いたモデルに依存して結果が変わってしまう可能性が高く、実際には共変量がバランシングしないことがある

<br />
データが元からバランシングしているのであれば、傾向スコアマッチングは悪影響を及ぼし、データが元からバランシングしていないのであれば、傾向スコアマッチングがバランシングを改善したとしても、そのようなデータはそもそも因果推論に適していない

これを**傾向スコアマッチングのパラドックス**という

## King and Nielsenの主張の解釈（1/2） {#Ch_11_13_3}

この主張を解釈するには、2つの点に注意が必要である

まず初めに、**King and Nielsenが問題視しているのは、傾向スコアマッチングであって、傾向スコアそのものではない点**である

したがって、第12章で扱う傾向スコアによる層化解析法および重み付け法は批判の対象になっていない

<br />
次に、King and Nielsenは、1983年～2015年までに出版された傾向スコアを用いた実証研究論文について、JSTORから230編の学術論文を無作為に抽出して調査した

**これら230編のうち、わずか6%だけが何らかのバランシングのチェックを行っており、80%は最近隣法マッチング（貪欲マッチング）による1対1の傾向スコアマッチングを用いていた**

本章で解説したとおり、傾向スコアマッチングには、距離の求め方、マッチング方法、復元と非復元の選択など、さまざまなことを考慮しなければいけなかった

しかし、King and Nielsenはの批判している傾向スコアマッチングとは、最近隣法マッチング（貪欲マッチング）による非復元の1対1マッチングのことであり、必ずしもすべての傾向スコアマッチングを批判しているわけではない

## King and Nielsenの主張の解釈（2/2） {#Ch_11_13_3}

したがって、King and Nielsenの主張それ自体は正しいものの、その適用範囲はきわめて限定的というのが、大勢の見方である

すなわち、King and Nielsenの主張は、**最近隣法マッチング（貪欲マッチング）の1対1の傾向スコアマッチングのような、単純な手法を機械的に適用してはいけない**という教訓と理解できる


## King and Nielsenの主張に対する反論 {#Ch_11_13_4}

実際、Guo, Fraser, and Chenは、**共変量のバランシングの確認が重要であり、共変量のバランスがとれていないことは、傾向スコアマッチングを使用したことが原因ではない**と述べている

Webster-Clark et al.は、復元の1体多マッチングが処置効果を最も精度高く推定できるとしてる

Nguyen et al.は、共変量のバランシングを測る標準化平均差が0.1未満になるように、傾向スコアのモデリングをする必要があると指摘している

Jannは、傾向スコアマッチング後の解析モデルにおいて回帰調整（regression adjustment）を行う方法がよいことをシミュレーションで示している

これは、実際に、Rubin and Thomas以来、推奨されている方法である

Ripollone et al.は、薬物疫学の分野での応用を念頭に置いて傾向スコアマッチングのパラドックスを検討したところ、マッチングにより共変量のインバランスは増加しないと結論付けている


## ローゼンバウムの見解 {#Ch_11_13_5}

傾向スコアの提案者であるローゼンバウムは、傾向スコアマッチングに関して、以下のとおりの見解を示している

傾向スコアだけによるマッチングでは、共変量の一致は保証されないので、そのための措置が必要になることがある

また、1対1のペアマッチングは、利用可能なデータを最大限に使用しているとは限らないので、データを柔軟に活用する方法が望ましい

よって、傾向スコアマッチングを適切に運用しさえすれば、問題はないものと考えられる


11.10節で導入したラブプロットで共変量のバランシングを評価することも大事である



# 11.14　質的研究のためのマッチング {#Ch_11_14}

## 質的研究のためのマッチング {#Ch_11_14_1}

本章は、傾向スコアマッチングに焦点を当てて解説をしてきた

傾向スコアマッチングは**処置群と統制群における共変量の分布が等しくなる方法であり、マッチングされた個体同士の共変量自体の値が等しいことは保証されていない**

<br />

一方、本章の冒頭で例示のために導入した表11.1は、質的研究におけるマッチングの例であった

質的研究におけるマッチングでは、個体同士の距離が近いものをマッチングする必要がある


したがって、そのような研究では傾向スコアマッチングを使うのではなく厳密マッチングまたは単純化厳密マッチング（CEM）を用いることが推奨されている





